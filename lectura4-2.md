# Document Clustering Based On Non-negative Matrix Factorization
En este paper se propone un método nuevo para realizar Document Clustering, el cuál se basa en utilizar factorización matricial no negativa. Document clustering es básicamente el agrupar distintos documentos de texto bajo una categoría, por lo que podría verse parecido a una clasificación. En el paper, describe de manera bastante rigurosa el como funciona el método propuesto, para luego evaluarlo frente a otros métodos de document clustering

En primer lugar, me gusta la intuición que da el paper de representar un documento como una combinación entre distintos tópicos, y el hecho de que los ejes no sean necesariamente ortogonales tiene mucho sentido si lo ponemos en un contexto real, ya que en muchos casos 2 tópicos, aunque sean claramente distintos, no serán completamente independientes, sino que estarán en cierta medida relacionados entre si. Esto se traduce en que si aumentamos en un eje de X tópico, algún tópico no ortogonal a este también aumentaría (aunque no en la misma medida). Por ejemplo, si hablamos acerca de un tópico como Python, también podriamos esperar que aumentara un tópico como Javascript, dado que si bien claramente no son de la misma categoría, si hay similitudes en cuanto al lenguaje que se utiliza para hablar de ellos y por lo tanto sería imposible que fueran totalmente independientes (es decir, ortogonales). Sin embargo, una cosa que creo que podría ser interesante es probar no solo con una representación como combinación lineal, sino que agregarle componentes no lineales (como puede ser una función ReLU) para así modelar de todavía mejor forma cada documento. Esto viene de que seguramente el problema de clasificar documentos no es un problema lineal, por lo que tiene sentido agregar componentes no lineales para modelar mejor cada documento

Algo que considero que hubiese sido interesante es un mayor análisis de la matriz U para ver que tipo de clusters esta formando. En todo momento del paper, se testea y se asume en general que uno conoce los K clusters para los cuales uno puede clasificar un documento (en los 2 datasets los documentos ya vienen clasificados con un label definido), sin embargo muchos otros conjuntos de documentos puede que no posean un label, y para estos casos puede ser interesante ver que tópicos comienza a "encontrar" el algoritmo. Esto creo que es posible ya que en el desarrollo matemático nunca se dice que uno deba conocer específicamente que clusters existen, sino que dado un parámetro K igual al número de clusters el algoritmo encuentra una factorización que forme exactamente K clusters. Por lo tanto, uno puede darle algún número K y a continuación estudiar las columnas uj de la matriz U (la cual posee en cada entrada i de la columna un valor que representa que tanto pertenece la palabra i al cluster j) para poder obtener, a partir de las palabras más relevantes para dicho cluster, una posible idea entendible por los humanos del tópico que se haya encontrado en dicho cluster. Esto sería finalmente utilizar el mismo algoritmo pero para un problema distinto de clustering en donde no se conozcan a priori los labels de cada cluster, y el algoritmo tenga que encontrarlos por su cuenta.

Finalmente, vi que en la evaluación se excluyeron ciertos documentos de los datasets debido a que pertenecían a clusters muy pequeños, o bien porque pertenecían a más de una categoría. Si bien entiendo que hicieron esto para poder evaluar de mejor forma el rendimiento del método dado que los documentos tendrían un único label correcto, creo que hubiera sido interesante probar como se comporta específicamente en los casos en donde un documento pertenece a más de una categoría. Así se podría saber si el algoritmo es capaz de identificar correctamente más de un sólo tópico (que sería no ver solamente el eje de mayor valor sino otros que sobrepasen cierto threshold), e incluso ver si puede encontrar más labels en documentos que sólo tengan clasificado 1 label, pero que sea coherente que además pertenezcan a otro label más.
