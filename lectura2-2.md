# BPR: Bayesian Personalized Ranking from Implicit Feedback

En este paper se presenta básicamente un método de optimización (o mejor dicho un criterio de optimización) que proviene de darle un enfoque bayesiano al problema de recomendación con feedback implícito. Lo interesante de esto es que se puede aplicar a distintos métodos para recomendar, como factorización matricial o kNN, y probablemente sea posible aplicarlo a otros más. 

Primero que nada, me gusto bastante como dan fundamento matemático a casi la totalidad del paper, desde formalizar matemáticamente el problema de recomendación con feedback implícito, hasta toda la fundamentación y desarrollo matemático del método bayesiano que utilizan. Lo único que si me hubiera gustado es que en la sección 3.1, en donde formalizan el problema, que explicasen un poco acerca de Iu+ y Ui+, aparte de solo mencionarlos por conveniencia. 

La manera de crear el dataset me parece muy ingeniosa, ya que ataca a uno de los principales problemas del feedback implícito, que es el que sólo haya feedback positivo. El único problema que le veo a la forma que utilizaron es el supuesto de que si un usuario vio un determinado item i, entonces lo prefiere por todo el resto de items que no ha visto (o mejor dicho, de que no ha dado feedback implícito acerca de este). Este supuesto considero que puede ser en muchos casos no muy real (si por ejemplo una persona simplemente no haya encontrado algún item que le guste mucho), pero aun así creo que es un buen baseline para armar el dataset dado que si es cierto que, por lo general, uno parte buscando o haciéndole click a las cosas que le gusten más por sobre las que no, por lo que la cantidad de veces que ocurra el ejemplo que di anteriormente es mucho menor que el caso bueno en donde realmente el usuario prefiere el item para el cuál a dado feedback implícito.

Me gusta que hayan agregado el pseudo codigo de LearnBPR, ayuda bastante a comprender como funciona incluso sin saber mucho acerca de descenso de gradientes.

4.3.2: Porque si el número de items es muy grande es mejor aprender una factorización HHtraspuesta de C ? No lo desarrollan, ni dan explicaciones de porque es así, ni citan algún paper en ese lugar en donde se explique el por qué.

En la parte de evaluación, creo que falto comparar con respecto al método MMMF, más que nada porque en el apartado anterior discuten acerca de este método y como se compara con LearnBPR, sin embargo luego no demuestran empíricamente en la experimentación que su método sea mejor, por lo que esa parte de discución considero que queda bastante al aire.

Finalmente, en el problema de evaluación con el dataset de netflix ¿Porqué querriamos predecir si un usuario va a darle rating o no a una película? Creo que el problema de recomendación esta mal formulado aquí, ya que si bien dado los datos que se poseen es mucho más fácil y directo predecir eso, lo que queremos al final es recomendarle a un usuario películas que les puedan gustar, y no películas a las que es probable que les de rating. No tiene sentido para el usuario, por ejemplo, predecir 10 películas a las que efectivamente el usuario les vaya a dar un rating, si el rating para esas 10 películas finalmente es un 1. 
