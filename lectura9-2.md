# Carousel Personalization in Music Streaming Apps with Contextual Bandits
Este paper trata, como lo dice el título, acerca de un framework para personalizar los "carruseles" en aplicaciones de streaming de música utilizando la técnica de contextual multi-armed bandits. En el trabajo se toman en cuenta las distintas características del carrusel, y además se evalúan distintas técnicas para seleccionar los brazos, como por ejemplo Thompson Sampling, UCB, e-greedy entre otros.

En primer lugar, me pareció muy inteligente la manera en que capturan las características de los carruseles en aplicaciones en producción, dado que si bien el carrusel es simplemente una forma de mostrar la información, esto afecta directamente en que items va a ver el usuario y cuales no, incluso aunque hayan sido recomendados dentro de la lista del carrusel. Para esto, ellos utilizan un modelo basado en cascada, en donde básicamente asumen que el usuario vio por lo menos los primeros elementos que son mostrados en pantalla, mientras que el resto de los elementos asumen que los vió solamente si el usuario reprodujo dicho elemento o bien uno posterior a ese elemento en la lista (por ejemplo, si el usuario reprodujo la séptima canción, el modelo asume que vió todas las recomendaciones hasta la séptima, mientras que las canciones posteriores a la séptima no las vio). Me parece bastante acertado este modelo ya que, si bien obviamente no va a poder ser 100% fiel a la realidad, da evidencia concreta de que recomendaciones el usuario vio, ya que si elige una canción necesariamente debe haber visto las recomendaciones pasadas dado la estructura que tiene el carrusel, el cuál no permite saltarse items, sino que deben ser vistos todos en orden. Este método es mucho mejor que asumir que el usuario vio todas las recomendaciones, ya que en la mayoría de los casos esto no es verdad, y asumirlo puede llevar a pensar que ciertas canciones no le gustan al usuario y que fueron malas recomendaciones, cuando en realidad simplemente ocurrió que el usuario no alcanzó a verla, y por lo tanto no pudo seleccionarla. 

En relación a lo último, una cosa que considero que podría ser relevante a la hora de evaluar este modelo en un estudio online es que, en muchos casos, la cantidad inicial de recomendaciones que ve el usuario (el Linit del paper) puede variar dependiendo de la pantalla que tenga el dispositivo, dado que van a caber una distinta cantidad de elementos al mismo tiempo (por ejemplo, en una pantalla de celular podrían caber unos 3 elementos solamente dado que es más pequeña, mientras que en una tele o monitor podrían caber bastantes más dado que son mucho más anchos), por lo que el parámetro Linit ya no sería un número fijo sino que variaría dependiendo de que dispositivo este usando actualmente el usuario. En el paper no se menciona que hayan hecho este arreglo para el estudio online, por lo que aprovecho para mencionarlo aquí como comentario.

Una cosa que me pareció muy interesante es la importancia que tienen los distintos algoritmos de selección y como estos pueden afectar de manera considerable la métrica de cumulative regret. Dado que en el paper evalúan bastantes algoritmos, se puede ver como elegir un buen algoritmo de selección, independiente de el resto de factores, puede llevar a una importante mejora en la performance del multi-armed bandit. En específico vemos que en el paper comparan muchos métodos, por lo que es bastante valioso para poder comparar y elegir el mejor método disponible para elegir los distintos brazos.
