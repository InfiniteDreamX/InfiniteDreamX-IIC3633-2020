# Evaluating Recommendation Systems
Este paper trata principalmente acerca del proceso de evaluación de un sistema recomendador. Abarca principalmente la metodología de la experimentación en la seccion 2 del paper, y profundiza en las distintas propiedades con las que uno puede experimentar en la sección 3. Es más una review del estado del arte en la evaluación de sistemas, asi como recomendaciones de como llevar a cabo dichas evaluaciones.

En primer lugar me gustaría mencionar algo que me gustó bastante que se repetía a lo largo de todo el estudio, y es que se preocupaban del testeo no sólo en un ámbito de laboratorio e investigación, si no que también testeo en ambientes reales de producción (como lo es la Online Evaluation) en donde se tratan aspectos no tan comunes como el efecto de la interfaz en el análisis de la efectividad del sistema y los posibles supuestos que se pueden realizar de las coductas del usuario (Por ejemplo, cuando menciona acerca de que, si la interfaz es como una lista en donde se presentan 10 elementos y el usuario escoge, por ejemplo, los elementos 2, 6, 11 , podemos suponer que el resto de elementos no escogidos del 1-20 no le interesan). Esto lo considero bastante relevante ya que explica factores relevantes que normalmente pasarían desapercibidos en una investigación sin implementación de producción, pero que son bastante relevantes a la hora de poner en marcha un sistema recomendador en un comercio real. 

En la seccion 2.2.1 se habla acerca de los bias existentes en los datasets, y se mencionan técnicas para lidiar con estos como el resampling y el reweighting para poder corregir dichos bias. Sin embargo, considero que hubiese sido interesante poder profundizar un poco más en dichas técnicas más que sólo mencionarlas, ya que tal como mencionaban en el paper, casi siempre uno va a tener que lidiar con estos problemas al momento de testear un sistema recomendador, por lo que ese conocimiento de como tratar con los bias es importante. En específico, hubiera sido bueno tener una breve explicación de porqué dichas técnicas funcionan, y cuándo es conveniente usarlas y cuándo no. De esta forma no hubiese quedado tan al aire este aspecto, y se podría haber tenido cierto guideline de cuando y cómo usar estas técnicas para lidiar con el bias.

En la sección 2.4.1, se menciona el uso de p-values para medir que tan confiable es un test. Si bien estoy de acuerdo en que son útiles, en el párrafo practicamente lo único que hacen es dar una definición sacada de un libro de inferencia estadística de esta técnica, siendo que lo que uno esperaría (y que de hecho se hace para el resto del artículo) es un análisis un poco más en profundidad del metodo en el contexto específico de evaluar sistemas recomendadores y los tests a dichos sistemas. De esta manera, hubiera quedado mucho más claro el cómo hacer un p-value test para los tests de RecSys, así como también las implicancias que tiene el p-value test específicamente para los tests presentados anteriormente en el paper (offline, user study, online).

En la sección 3.3.3, se menciona el problema de la "Cold start", el cuál es básicamente las dificultades que tiene un sistema para recomendar tanto a usuarios nuevos como items nuevos. En este apartado, creo que le dieron muy poco énfasis, dado que todo lo que hicieron fue discutir acerca de como definir los Cold items, pero no se discutió nada acerca de métodos para lidiar con estos problemas, ni tampoco métodos específicos para poder evaluar performance en dichos cold items. Este problema en particular lo considero muy importante, ya que si no se trata bien nos encontraremos en una situación en donde un sistema no va a poder dar recomendaciones buenas para los nuevos usuarios, con lo cuál no va a lograr atraer nuevo público a la posible aplicación. Lo mismo con los items, recomendaría siempre los mismos y los nuevos nunca serían recomendados, provocando un vicio en las recomendaciones. 

Como comentario final, creo que toda la sección 3 del paper fue bastante interesante, ya que identifica claramente todos los posibles aspectos a evaluar de un sistema recomendador tomando en cuenta la interaccion con los usuarios (por ejemplo "Trust" es una característica que quizás en muchos estudios se olvida, dado que sólo se puede medir de manera concreta en user studies y en online), así como también aspectos directamente del sistema y su implementación (como por ejemplo la Scalability). Esto lo considero bastante valioso, ya que de esta manera uno puede identificar con claridad la importancia de cada una de estas características y así poder elegir cuál de estas es más importante para un determinado caso, para luego poder hacer los tests pertinentes para evaluar dichas catacterísticas por sobre otras que quizás no sean tan relevantes en algunas situaciones. 
